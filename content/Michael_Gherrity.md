---
title: Michael Gherrity
---
**[Home](Home "Home") \* [People](People "People") \* Michael Gherrity**


**Michael (Mike) Gherrity**,  

an American computer scientist and AI-researcher from the [University of California, San Diego](https://en.wikipedia.org/wiki/University_of_California,_San_Diego). He defended his Ph.D. in 1993 - *A Game Learning Machine*, elaborating on [SAL](SAL "SAL") ([Search](Search "Search") and [Learn](Learning "Learning")) <a id="cite-note-1" href="#cite-ref-1">[1]</a>, his [General Game Playing](General_Game_Playing "General Game Playing") program. While applying a [move generator](Move_Generation "Move Generation"), and losing if own king is captured as sole domain specific knowledge, it was the first chess program used [Temporal Difference Learning](Temporal_Difference_Learning "Temporal Difference Learning") <a id="cite-note-2" href="#cite-ref-2">[2]</a>. In a match of 4200 games against [GNU Chess](GNU_Chess "GNU Chess") (One second per move), it started to play random moves within its two [ply](Ply "Ply") search plus [Consistency Search](index.php?title=Consistency_Search&action=edit&redlink=1 "Consistency Search (page does not exist)"), a generalized [Quiescence Search](Quiescence_Search "Quiescence Search") <a id="cite-note-3" href="#cite-ref-3">[3]</a>, but learned to play reasonable, but still weak chess. It archived eight draws, apparently due to a [repetition](Repetitions "Repetitions") detection bug in GNU Chess <a id="cite-note-4" href="#cite-ref-4">[4]</a>.



### Contents


* [1 Selected Publications](#selected-publications)
* [2 Forum Posts](#forum-posts)
* [3 External Links](#external-links)
* [4 References](#references)






<a id="cite-note-5" href="#cite-ref-5">[5]</a>



* Michael Gherrity (**1989**). *[A Learning Algorithm for Analog, Fully Recurrent Neural Networks](https://ieeexplore.ieee.org/document/118645)*. [IEEE IJCNN 1989](IEEE "IEEE")
* [Richard K. Belew](https://scholar.google.com/citations?user=vqrY_hgAAAAJ&hl=en), Michael Gherrity (**1989**). *Back Propagation for the Classifier System*. [ICGA 1989](https://dblp.uni-trier.de/db/conf/icga/icga1989.html)
* Michael Gherrity (**1993**). *A Game Learning Machine*. Ph.D. thesis, [University of California, San Diego](https://en.wikipedia.org/wiki/University_of_California,_San_Diego), advisor [Paul Kube](Mathematician#PKube "Mathematician"), [pdf](http://www.gherrity.org/thesis.pdf), [pdf](http://www.top-5000.nl/ps/A%20game%20learning%20machine.pdf)
* Michael Gherrity, [Paul Kube](Mathematician#PKube "Mathematician") (**1993**). *Quiescent Search is Beneficial.* Technical Report CS93-289, [University of California, San Diego](https://en.wikipedia.org/wiki/University_of_California,_San_Diego)


## Forum Posts


* [Subject: Re: Game Learning](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/games/doc/strategy.txt) by Mike Gherrity, [ai-repository](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/), July 1, 1994 <a id="cite-note-6" href="#cite-ref-6">[6]</a>
* [DB Tweaking Between Games](https://groups.google.com/d/msg/rec.games.chess.computer/jZ5A9ShxzYU/vX50umDt5NsJ) by Mike Gherrity, [rgcc](Computer_Chess_Forums "Computer Chess Forums"), May 13, 1997 » [Kasparov versus Deep Blue 1997](Kasparov_versus_Deep_Blue_1997 "Kasparov versus Deep Blue 1997")
* [Learning necessary for chess champion?](https://groups.google.com/d/msg/rec.games.chess.computer/SzZAbOQFOtU/erRKS26ISWMJ) by Mike Gherrity, [rgcc](Computer_Chess_Forums "Computer Chess Forums"), May 16, 1997


## External Links


* [Michael Gherrity Home](http://www.gherrity.org/)
* [SAL](http://satirist.org/learn-game/systems/sal.html) from [Machine Learning in Games](http://satirist.org/learn-game/) by [Jay Scott](Jay_Scott "Jay Scott")
* [The Mathematics Genealogy Project - Michael Gherrity](http://genealogy.math.ndsu.nodak.edu/id.php?id=103352)


## References


1. <a id="cite-ref-1" href="#cite-note-1">[1]</a> [SAL](http://satirist.org/learn-game/systems/sal.html) from [Machine Learning in Games](http://satirist.org/learn-game/) by [Jay Scott](Jay_Scott "Jay Scott")
2. <a id="cite-ref-2" href="#cite-note-2">[2]</a> [Marco Block](Marco_Block-Berlitz "Marco Block-Berlitz"), Maro Bader, [Ernesto Tapia](http://page.mi.fu-berlin.de/tapia/), Marte Ramírez, Ketill Gunnarsson, Erik Cuevas, Daniel Zaldivar, [Raúl Rojas](Ra%C3%BAl_Rojas "Raúl Rojas") (**2008**). *Using Reinforcement Learning in Chess Engines*. Concibe Science 2008, [Research in Computing Science](http://www.micai.org/rcs/): Special Issue in Electronics and Biomedical Engineering, Computer Science and Informatics, Vol. 35, [pdf](http://page.mi.fu-berlin.de/block/concibe2008.pdf), 1.1 Related Work
3. <a id="cite-ref-3" href="#cite-note-3">[3]</a> [Don Beal](Don_Beal "Don Beal") (**1989**). *Experiments with the Null Move.* [Advances in Computer Chess 5](Advances_in_Computer_Chess_5 "Advances in Computer Chess 5"), a revised version is published (**1990**) under the title *A Generalized Quiescence Search Algorithm*. [Artificial Intelligence](https://en.wikipedia.org/wiki/Artificial_Intelligence_%28journal%29), Vol. 43, No. 1
4. <a id="cite-ref-4" href="#cite-note-4">[4]</a>  Michael Gherrity (**1993**). *A Game Learning Machine*. Ph.D. thesis, [University of California, San Diego](https://en.wikipedia.org/wiki/University_of_California,_San_Diego), advisor [Paul Kube](Mathematician#PKube "Mathematician"), [pdf](http://www.gherrity.org/thesis.pdf), [pdf](http://www.top-5000.nl/ps/A%20game%20learning%20machine.pdf)
5. <a id="cite-ref-5" href="#cite-note-5">[5]</a> [dblp: Michael Gherrity](https://dblp.uni-trier.de/pers/hd/g/Gherrity:Michael)
6. <a id="cite-ref-6" href="#cite-note-6">[6]</a> [Barney Pell](Barney_Pell "Barney Pell") (**1993**). *Strategy Generation and Evaluation for Meta-Game Playing*. Ph.D: thesis, [Trinity College, Cambridge](https://en.wikipedia.org/wiki/Trinity_College,_Cambridge), [pdf](http://www.barneypell.com/papers/pell-thesis.pdf)

**[Up one level](People "People")**







 
